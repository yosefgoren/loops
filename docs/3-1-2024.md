## Next Data Summery
Create a histogram + table:

Experiment types:
* Serial - each histogram on serial dataset runtimes
* Parallel - ... parallel ...

Histogram types:
* Histogram 1 - Exact (0-dist) (baseline performance is 20%)
* Histogram 2 - Close (1-dist) (baseline performance is ~60% (a little less due to edges 1 and 5))

Bar Types:
* zero-shot - validation of base model without examples
* fewshot-1 - validation of base model with 1 example
* fewshot-2 - ... 2 examples
* fewshot-5 - ... 5 examples
* base-fine-tune - fine-tuned model on base dataset
* augmented-fine-tune - ... augmented ...


## Augmentation Round 2
Re-run the augmentation to generate more than one example, but decrease the 'temprature' example to be less.
Gal is running the fine-tuning like:
```python
try:
    response = client.chat.completions.create(
        model="gpt-4o-mini-2024-07-18-ompcpp_train_augmented_shuffle_ws_batch1",
        messages=message_text,
        temperature=temperature_test,
        max_tokens=1, # logprobs=True, top_logprobs=5,p
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        stop=None
    )
except openai.NotFoundError as e:
    print(f"Error: {e}")
    print("Deployment not found. Check your Azure OpenAI deployment status.")
    sys.exit(1)
```

### Future Directions Updates
* Leave the direction of playing with whitespaces.
* Continous Fine-Tuning: First fine tune the model to predict serial performance, then fine-tune to predict parallel performance.
    The initial fine-tuning will be with the same code, but specifying that there is 1 thread.
    The classes which the model will be requested to predict will be the total CPU usage of each sample (runtime*num_core) which will be normallized and classified to categories.